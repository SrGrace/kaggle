{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/srgrace/flower-recognition-hackerearth?scriptVersionId=89247586\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input/he_challenge_data/data\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Need pretrainedmodels to load the pretrained Cedene models into fastai.\n### https://github.com/Cadene/pretrained-models.pytorch","metadata":{}},{"cell_type":"code","source":"!pip install pretrainedmodels","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.models import *\nimport pretrainedmodels\n\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.vision.models import *\nfrom fastai.vision.learner import model_meta\nimport fastai\n\nfrom utils import *\nimport sys\nimport torch\nfastai.__version__","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lis = os.listdir('../input/he_challenge_data/data/train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/he_challenge_data/data/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/he_challenge_data/data/train\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## test filenames to be used to create final submission.\nfilenames = os.listdir('../input/he_challenge_data/data/test')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/he_challenge_data/data/train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfms = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False,xtra_tfms=[cutout()])\ndata = (ImageList.from_csv(path, csv_name = '../train.csv', suffix='.jpg')\n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms, size=400)\n        .databunch(num_workers=0,bs=8)) \n\ntfms1 = get_transforms(flip_vert=False,max_zoom=1.0,max_warp=0,do_flip=False)\ndata1 = (ImageList.from_csv(path, csv_name = '../train.csv', suffix='.jpg')\n        .split_by_rand_pct()              \n        .label_from_df()            \n        .add_test_folder(test_folder = '../test')              \n        .transform(tfms1, size=400)\n        .databunch(num_workers=0,bs=8)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## to see the images in train with there labels\ndata.show_batch(rows=3, figsize=(8,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## print the target classes\nprint(data.classes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = cnn_learner(data, models.resnet152, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defaults.device = torch.device('cuda')\n\n## training with one cycle which used cyclic learning rate and learning rate annhelling\nlearn.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.lr_find()\nlearn.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds,_ = learn.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn1 = cnn_learner(data, models.densenet161, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn1.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn1.unfreeze()\nlearn1.lr_find()\nlearn1.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds1,_ = learn1.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2 = cnn_learner(data, models.resnet101, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn2.unfreeze()\nlearn2.lr_find()\nlearn2.fit_one_cycle(2, max_lr=slice(1e-6,1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds2,_ = learn2.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn3 = cnn_learner(data, models.densenet201, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn3.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn3.unfreeze()\nlearn3.lr_find()\nlearn3.fit_one_cycle(2, max_lr=slice(1e-6, 1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds3,_ = learn3.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn4 = cnn_learner(data, models.densenet169, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn4.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn4.unfreeze()\nlearn4.lr_find()\nlearn4.fit_one_cycle(2, max_lr=slice(1e-6, 1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds4,_ = learn4.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn5 = cnn_learner(data, models.resnet50, metrics=[error_rate, accuracy], model_dir=\"/tmp/model/\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn5.fit_one_cycle(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learn5.unfreeze()\n# learn5.lr_find()\n# learn5.fit_one_cycle(2, max_lr=slice(1e-6, 1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds5,_ = learn5.TTA(ds_type=DatasetType.Test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## create the submission file \nlabelled_preds = []\nensemble_preds = preds + preds1 + preds2 + preds3 + preds4 # + preds5 + preds2\nfor pred in ensemble_preds:\n    labelled_preds.append(int(np.argmax(pred))+1)\n\nsubmission = pd.DataFrame(\n    {'image_id': filenames,\n     'category': labelled_preds,\n    })\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['image_id'] = submission['image_id'].apply(lambda x:x.split('.')[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = submission.sort_values(by = ['image_id'], ascending = [True])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## To download the submission file without Commiting the kernel.\n\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"subm_5_learn_2_cycle.csv\"):  \n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ncreate_download_link(submission)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.mkdir('saved_models')\n# file_path = '../saved_models'\ntorch.save(learn, 'resnet152.pth')\ntorch.save(learn1, 'densenet161.pth')\ntorch.save(learn2, 'resnet101.pth')\ntorch.save(learn3, 'densenet201.pth')\ntorch.save(learn4, 'densenet169.pth')\n# torch.save(learn5, 'resnet50.pth')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}